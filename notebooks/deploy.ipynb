{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying image classification as REST API\n",
    "\n",
    "This notebook shows how to publish a trained image classification model as a Rest API service. We will start with local deployment (which uses docker), and then illustrate how easy it is using the same approach to instead publish to an Azure Container Service (ACS) with Kubernetes container management. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "- All numbered scripts until `5_evaluate.py` have to be executed as is described in part 1 of the documentation. This trains the DNN/SVM model which will get deployed.\n",
    "- We assume the reader is familiar with the excellent deployment section of the [IRIS tutorial](https://docs.microsoft.com/en-us/azure/machine-learning/preview/tutorial-classifying-iris-part-3) and the [Model management setup how-to guide](https://docs.microsoft.com/en-us/azure/machine-learning/preview/model-management-configuration).\n",
    "- Local deployment requires a Docker server to be installed and running on the local machine. See the [Docker homepage](https://www.docker.com) or the AML Workbench [Troubleshooting guide](https://docs.microsoft.com/en-us/azure/machine-learning/preview/known-issues-and-troubleshooting-guide) for installation instructions.\n",
    "Note that, at the time of writing, Docker supports the Windows 10 Operating System but not Windows Server 2016 which is running on the Window's Deep Learning Virtual Machines. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rest API Implementation\n",
    "The Rest API is implemented in the `deploymain.py` script using these three functions:\n",
    "- Init(): loads the trained DNN/SVM model into memory after the Rest API is deployed.\n",
    "- Run(): takes an image (in base64 encoding) as input, runs the full image classification pipeline including evaluating the DNN/SVM model, and returns the classification scores as json encoded string.\n",
    "- Main(): can be used locally to test and debug the init() and run() functions before deployment. It creates a random 5x5 pixel RGB image, converts it to a base64 encoded string, which is then used as input to the run() function.\n",
    "\n",
    "During deployment, a [swagger specification](https://en.wikipedia.org/wiki/OpenAPI_Specification) file can optionally be specified which defines how to describe and consume the web service. This swagger file is called `deployserviceschema.json` and was automatically created running `deploymain.py` (see the call to `generate_schema()`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "Various files are required by the web-service, including, among others, the trained DNN or SVM models. These files are copied in the code below to a local folder called *tmp*. During deployment, this folder is re-created on the node which runs the Rest API: note how the script `deploymain.py` loads files from that *tmp* folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(\".\")\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"libraries\")\n",
    "sys.path.append(\"../libraries\")\n",
    "from helpers import *\n",
    "from PARAMETERS import procDir\n",
    "\n",
    "# Set files source and destination information\n",
    "model_files_to_copy   = [\"cntk_fixed.model\", \"cntk_refined.model\", \"lutId2Label.pickle\", \"svm.np\"]\n",
    "code_files_to_copy    = [\"deploymain.py\", \"deployserviceschema.json\"]\n",
    "library_files_to_copy = [\"helpers.py\", \"helpers_cntk.py\", \"utilities_CVbasic_v2.py\", \"utilities_general_v2.py\"]\n",
    "model_folder   = procDir \n",
    "code_folder    = \"../scripts\"\n",
    "library_folder = \"../libraries\"\n",
    "deploy_folder  = os.path.join(code_folder, \"tmp\")\n",
    "\n",
    "# Copy files\n",
    "makeDirectory(deploy_folder)\n",
    "copyFiles(model_files_to_copy,   model_folder,   deploy_folder)\n",
    "copyFiles(library_files_to_copy, library_folder, deploy_folder)\n",
    "copyFiles(code_files_to_copy,    code_folder,    deploy_folder)\n",
    "print(\"Files copied to deployment folder: \" + deploy_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Local deployment\n",
    "We now describe how to deploy the trained model as a Rest API which runs inside a docker container on the local machine.\n",
    "All commands shown below need to be executed from the AML Workbench command prompt which can be opened via **File**->**Open Command Prompt**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps:\n",
    "1. Change to the directory which contains the scripts:\n",
    "   ```sh \n",
    "   cd scripts\n",
    "   ```\n",
    "2. Set deployment target to local. Note that the Workbench might prompt the user to login first using the command `az login`. \n",
    "   ```sh\n",
    "   az ml env local\n",
    "   ```  \n",
    "\n",
    "3. Create Rest API service (this can take 10-20 minutes). Use the command below as-is if `classifier=svm` in `deploymain.py`, but if `classifier=dnn` then change *cntk_fixed.model* to *cntk_refined.model*.\n",
    "   ```sh\n",
    "   az ml service create realtime -c ../aml_config/conda_dependencies.yml -f deploymain.py -s deployserviceschema.json -n imgclassapi1 -v -r python -d tmp/helpers.py -d tmp/helpers_cntk.py -d tmp/utilities_CVbasic_v2.py -d tmp/utilities_general_v2.py -d tmp/svm.np -d tmp/lutId2Label.pickle --model-file tmp/cntk_fixed.model\n",
    "   ```\n",
    "4. Test the Rest API directly from the command prompt:\n",
    "   ```sh\n",
    "   az ml service run realtime -i imgclassapi1 -d \"{\\\"input_df\\\": [{\\\"image base64 string\\\": \\\"iVBORw0KGgoAAAANSUhEUgAAAAUAAAAFCAIAAAACDbGyAAAAFElEQVR4nGP8//8/AxJgYkAFpPIB6vYDBxf2tWQAAAAASUVORK5CYII=\\\"}]}\"\n",
    "   ```\n",
    "\n",
    "5. Obtain information of the Rest API by running:\n",
    "   ```sh\n",
    "   az ml service usage realtime -i imgclassapi1\n",
    "   ```\n",
    "Note that this also outputs a *scoring url* which looks like (but is not identical) to *http://127.0.0.1:32773/score*. This url can be used in script `6_callWebservice.py` which shows how to call the REST API from python rather than the command line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloud deployment\n",
    "Deploying the image classification service to Azure is very similar compared to the local deployment described above. The main difference is that an Azure Container Service needs to be created first. The actual deployment steps are then identical:\n",
    "\n",
    "### Steps\n",
    "- Simply follow the all the instructions in the [model management setup how-to guide](https://docs.microsoft.com/en-us/azure/machine-learning/preview/model-management-configuration) to set up the cloud deployment environment. Be careful when creating an Azure Container Service to delete it again once not needed anymore.\n",
    "- Then run all steps except for step 2 as explained in the *local deployment* section. \n",
    "\n",
    "**Example:**\n",
    "1. Register the environment provider:\n",
    "   ```sh\n",
    "   az provider register -n Microsoft.MachineLearningCompute\n",
    "   az provider register -n Microsoft.ContainerRegistry \n",
    "   ```\n",
    "\n",
    "2. Create an ACS cluster (may take 10-20 minutes to be completely provisioned):\n",
    "   ```sh\n",
    "   az ml env setup --cluster -l westcentralus -n acsdeployment\n",
    "   ```\n",
    "3. Find resource group and cluster name in the list of compute targets (look for entry with \"current mode: cluster\"):\n",
    "   ```sh\n",
    "   az ml env list to see compute targes\n",
    "   ```\n",
    "4. Specify which compute target to use for 'cloud' deployment (this also returns the url for the Kubernetes dashboard): \n",
    "   ```sh\n",
    "    az ml env set -n pabuehledeployvienna -g pabuehledeployviennarg\n",
    "   ```    \n",
    "5. Switch from local to cluster deployment:\n",
    "   ```sh\n",
    "   az ml env cluster\n",
    "   ```             \n",
    "6. Repeat all steps in the *local deployment* section except for step 2 which sets the local deployment target. The Rest API name should resemble *imgclassapi1.pabuehledeployvienna-bf329684.westcentralus*.    \n",
    "      \n",
    "7. Update script `6_` with the new scoring url and with the service key obtained by running: \n",
    "   ```sh\n",
    "   az ml service keys realtime -i imgclassapi1.pabuehledeployvienna-bf327884.westcentralus\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean-up\n",
    "Finally, we need delete all files in the local (temporary) deployment folder *tmp*. If this is not done, then the project directory will be above the size-limit of 25 MBytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../scripts\\tmp\\cntk_fixed.model\n",
      "../scripts\\tmp\\cntk_refined.model\n",
      "../scripts\\tmp\\lutId2Label.pickle\n",
      "../scripts\\tmp\\svm.np\n",
      "../scripts\\tmp\\helpers.py\n",
      "../scripts\\tmp\\helpers_cntk.py\n",
      "../scripts\\tmp\\utilities_CVbasic_v2.py\n",
      "../scripts\\tmp\\utilities_general_v2.py\n",
      "../scripts\\tmp\\deploymain.py\n",
      "../scripts\\tmp\\deployserviceschema.json\n",
      "Files deleted from deployment folder : ../scripts\\tmp\n"
     ]
    }
   ],
   "source": [
    "deleteFiles(model_files_to_copy,   deploy_folder)\n",
    "deleteFiles(library_files_to_copy, deploy_folder)\n",
    "deleteFiles(code_files_to_copy,    deploy_folder)\n",
    "print(\"Files deleted from deployment folder : \" + deploy_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging\n",
    "These commands or guidelines can be helpful for understanding e.g. what caused a deployment error or why the deployed Rest API is not working:\n",
    "- Inspect the docker log for errors:\n",
    "    ```bash\n",
    "    docker ps -a  # this shows all docker containers with their respective ID\n",
    "    docker logs <containerid>\n",
    "    ```\n",
    "- List all deployed services: \n",
    "    ```bash\n",
    "    az ml service list realtime\n",
    "    ```\n",
    "- Wrap all code running in the Rest API within *try...except* statments. See the run() and init() functions in `deploymain.py` as an example. This way, should an error occured during an API call, a description of this error is returned to the user.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
